---
title: "A virtual ecological approach to modeling  uncertainties in paleoecology"
author:
  - name: "Quinn Asena"
    affiliation: "University of auckland, Cary Institute"
  - name: "George Perry"
    affiliation: "University of auckland"
  - name: "Janet Wilmshurst"
    affiliation: "Manaaki Whenua - Landcare Research"
date: today
bibliography: refs.bib
from: markdown+emoji
format:
  revealjs:
    theme: dark
    css: custom.css
    preview-links: true
    highlight-style: github
    slide-number: c/t
    width: 1600
    height: 900
    embed-resources: true
title-slide-attributes:
  # data-background-color: "#1a1e43"
  data-background-color: "#0e4b52ff"
---


# Uncertainties in palaeoecology

<br>


- [Link to slides](https://quinnasena.github.io/neotoma-2025-talk/slides#/title-slide)

- [Link to website](https://quinnasena.github.io/quinn-asena-website)


## The problem

<br>

Proxy data are the product of multiple sources of uncertainty

<br>

- Environmental processes
  - bioturbation, taphonomy, variable sedimentation rates...

- Field and laboratory methods
  - core collection methods, sub-sampling strategy, pollen counting...

- Data processing methods
  - age-depth modelling, interpolation...


## The question: is the past recoverable from the data?

<br>

::::{.columns}
:::{.column}
### Why it matters

<br>

- Palaeoecology moving from descriptive to quantitative
- Palaeoecology to inform the future requires robust statistical approaches
- Advances in lab methods, data availability, and statistics are making more inferences possible

:::

:::{.column}
### What we can do about it

<br>

- One method to assess uncertainties is in simulation
- We use pseudoproxy modelling / Virtual ecology

:::
::::

## Approach

<br>

- Simulate core samples containing proxies mimicing the statistical properties of empirical data
- Simulate process and observer error that affect the data
- Assess how *statistical inferences* are affected by process and observer error


## Key concepts

- Virtual ecology [@zurell2010]
- Proxy system modelling [@evans2013]
- Pseudoproxy experiments [@mann2002]

- Other key refs: 
    - @blaauw2010a
    - @williams2011
    - @asena2024 :blush:
    - @asena2025 :see_no_evil:


## Take home message

<br>

- Proxy uncertainty is the counterpart to chronological uncertainty
- Proxy uncertainty and chronological uncertainty combine and are not separate.

## Virtual ecology


Virtual ecology is a framework for assessing sampling and analytical methods in simulation consisting of:

1. an ecological model that generates synthetic data

    1a. a degradation model

2. a simulated observational process (a sampling model) that samples the synthetic data

3. an analytical process or statistical model applied to both sets of data

4. an assessment of the results



## Virtual ecology and empirical ecology

<br>

:::: {.columns}
::: {.column width="50%"}
#### Perfect knowledege, imperfect world

- Known drivers and responses

- Known environmental and observational processes

- Advantage of benchmark/control data

- Advantage of replication

- Able to systematically introduce uncertainty
:::

::: {.column width="50%"}
#### Perfect world, imperfect knowledge

- Sampled data with no benchmark/control

- Advantage of being reality

:::
::::

## Proxy system modelling {.tight}

<br>

The process by which environmental change is recorded as an observable signal in an archive:

1. Environmental drivers (e.g., climatic variability)
2. A sensor (a physical, biological or chemical component of the system that responds to the environmental drivers)
3. An archive (the medium in which the response of the sensor is recorded such as a lake sediment)
4. Observations drawn from the archive

![](./imgaes/psm_light.png)


## Pseudoproxy experiments

<br>

Borrowing the term "*pseudoproxies*" from climatology:

- Pseudoproxies are simulated data or modified observational data
- Mimic the statistical properties of empirical data
- Pseudoproxy experiments are similar to virtual ecology


# Building the model

Let's follow a singe replicate case-study

## Simulating pseudoproxies

<br>

We set out to:

- Represent multiple interacting drivers
- Include underlying ecological dynamics (e.g., growth rates, niche tolerance)
- Generate a multi-species pseudoproxy record
- Recreate core formation processes of accumulation rates and time-span
- Virtually recreate the observational processes


## Simulating pseudoproxies

![](/imgaes/model-plot.svg){fig-align="center"}

## Ruining pseudoproxies

![](/imgaes/degradation_process.png){fig-align="center"}

## Extending the proxy system model framework

<br>

- Included a degradation (sub-)model to represent environmental processes


![](/imgaes/psm_extended_light.png)

## "Error-free" to degraded and sub-sampled

![](/imgaes/archive_half_half_walk_lin.png){fig-align="center"}

## Example of 20/200 randomly selected species

![](/imgaes/taxa_plot_N.png){fig-align="center"}


## Degraded and sub-sampled pseudoproxies

![](/imgaes/taxa_plot_mix10_sam10_cnt400.png){fig-align="center"}



# Analysing the outputs

## Analyses

<br>

Ok, now we have generated the data, let's analyse it. Two analyses:

- Fisher Information
- Principal curves

Demonstrating two scenarios with different driving environments.


## Analyses visualised

![](/imgaes/fi_prc_grad_vertical2.png){fig-align="center"}


## Recap! {.tight}

<br>

::::{.columns}
:::{.column width="50%"}

1. Environmental driver patterns over time (environment model)
2. Species that respond to the drivers (sensor model -- pseudoproxies)
3. Core representation: accumulation rate and time-span (archive model)
4. Core mixing (degradation model)
4. Sampling and counting process (observation model)
5. Analyse the pseudoproxies (assessment -- Virtual Ecology)

:::

:::{.column width="50%"}

Pervious slides followed:

- 1 scenario
  - we simulated four different driving environments
- 1 replicate
  - we simulated 30 replicates to account for stochasticity

:::
::::

# Question time


## Extending to multiple scenarios and replicates

<br>

Each replicate results in 1210 datasets from the 'error-free' to the most uncertain :scream:.

::::{.columns}
:::{.column width="40%"}

<br>

Across *replicates* for each of the 1210 datasets:

1. Extract features from the FI and PrC

    - feature analysis reduces the FI and PrC to one dimension

2. Calculate the distance between each dataset from the 'error-free' to the most uncertain

3. Make cool visulisations!
:::

:::{.column width="60%"}
![](/imgaes/miracle_occurs.png){width="80%" fig-align="right"}
:::
::::


## Think of it like this

- Each column is a Fisher Information (or PrC) series that we saw earlier

![](imgaes/3D-array.png){fig-align="center"}



## Feature analysis

- Feature Analysis for Time Series reduces the dimensions of the data to a set of comparable metrics ('features')
- Extracted 'features' are compared across uncertainty levels using Euclidian distance


## Assessing results (Virtual Ecology)

- Each uncertainty applied individually to Fisher Information

![](/imgaes/walk_lin_gradual_fisher_metrics_dotplot.png){fig-align="center"}


## Assessing results (Virtual Ecology)

- Two uncertainties applied to fisher information

![](/imgaes/walk_lin_gradual_fisher_two_dim_metrics_mean_plot.png){fig-align="center"}


# Question time

- We have 3-dimensional uncertainty plots but maybe we have seen enough plots for now!

## How does this help?

- Understand the relative effects of uncertainties
- Consider how we can mitigate uncertainty
- Take advantage of replicates and 'known' conditions
- Understand the effect of proxy uncertainty on the chronological placement of events


## Application to empirical

Simulation methods can be integrated with empirical studies to:

- _a priori_ help shape field sampling methods: e.g., number of core samples (across a region or local replication) required for a given research question.

- understand the sub-sampling and count resolution required to increase the likelihood of detecting a hypothesised signal in the data.

- accompany empirical study to test hypotheses about the underlying dynamics that may cause an observed pattern in the data.

- assess whether inferences made from the data are robust to uncertainty.

## Extensions

- Assessing error rates
- Chronological uncertainty combined with proxy uncertainty
- Extend underlying dynamics


# Final question time!

"All models are wrong, some are useful" @box1979


## Acknowledgements

- **George Perry** (University of Auckland)
- **Janet Wilmshurs** (Manaaki Whenua â€“ Landcare Research)

- Jack Williams (University of Wisconsin Madison)
- Tony Ives (University of Wisconsin Madison)

- Biological heritage Science Challenge (NZ) and the National Science Foundation (USA)


# References

::: {#refs}
:::



# Extras

## Think of it like this

- Fisher Information and PrC series

![](/imgaes/fi_prc_grad_vertical2.png){fig-align="center"}

## Think of it like this

- Each column is a Fisher Information (or PrC) series

![](imgaes/3D-array.png){fig-align="center"}


## Think of it like this

- Now, each column is a 'feature' describing the series

![](imgaes/3D-array-features.png){fig-align="center"}


## Think of it like this

- Now we have a distance matrix of every combination of uncertainty

![](imgaes/3D-array-distance.png){fig-align="center"}


## Assessing results

![](imgaes/walk_lin_gradual_fisher_three_dim_grid_plot.png){fig-align="center"}
